"""
Data utilities for loading and processing Bézier curve data from extracted JSON files.
================================================================================

Utilities to load bezier curve data generated by bezier_extraction.py and convert
it to tensors suitable for BezierAdapter processing.
"""

import json
import torch
import numpy as np
from typing import List, Dict, Tuple, Optional, Any
from pathlib import Path

from .utils import BezierCurve, BezierConfig, normalize_coordinates


def load_bezier_json(json_path: str) -> Dict[str, Any]:
    """
    Load bezier curve data from JSON file.
    
    Args:
        json_path: Path to bezier JSON file generated by bezier_extraction.py
        
    Returns:
        bezier_data: Dictionary containing curve data with structure:
            {
                "image_path": str,
                "characters": [
                    {
                        "character_id": int,
                        "contour_area": float,
                        "bounding_box": [x, y, w, h],
                        "bezier_curves": [[[x1, y1], [x2, y2], [x3, y3], [x4, y4]], ...],
                        "original_contour_points": int
                    },
                    ...
                ]
            }
    """
    with open(json_path, 'r', encoding='utf-8') as f:
        bezier_data = json.load(f)
    
    return bezier_data


def convert_json_to_bezier_curves(
    bezier_data: Dict[str, Any],
    config: Optional[BezierConfig] = None
) -> List[BezierCurve]:
    """
    Convert JSON bezier data to list of BezierCurve objects.
    
    Args:
        bezier_data: Output from load_bezier_json
        config: BezierConfig for processing parameters
        
    Returns:
        bezier_curves: List of BezierCurve objects
    """
    if config is None:
        config = BezierConfig()
    
    bezier_curves = []
    
    for character in bezier_data['characters']:
        # Assume image dimensions from dataset (typically 256x256 or similar)
        img_width, img_height = 256, 256  # Default, could be inferred from data
        
        for curve_idx, curve_points in enumerate(character['bezier_curves']):
            if len(curve_points) == 4:  # Ensure cubic Bézier
                # Convert to tensor and normalize coordinates
                control_points = torch.tensor(curve_points, dtype=torch.float32)
                
                # Normalize from pixel coordinates [0, 256] to [-1, 1]
                normalized_points = normalize_coordinates(
                    control_points,
                    source_range=(0, max(img_width, img_height)),
                    target_range=(-1, 1)
                )
                
                # Create BezierCurve object
                curve = BezierCurve(
                    control_points=normalized_points,
                    curve_id=f"char_{character['character_id']}_curve_{curve_idx}",
                    weight=1.0  # Could be based on contour area
                )
                
                bezier_curves.append(curve)
    
    return bezier_curves


def batch_bezier_curves(
    bezier_curves: List[BezierCurve],
    config: Optional[BezierConfig] = None
) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:
    """
    Convert list of BezierCurve objects to batched tensors.
    
    Args:
        bezier_curves: List of BezierCurve objects
        config: BezierConfig for batch parameters
        
    Returns:
        bezier_points: [B, max_curves, 4, 2] batched control points
        bezier_mask: [B, max_curves, 4] optional mask for valid points
    """
    if config is None:
        config = BezierConfig()
    
    # Limit number of curves
    num_curves = min(len(bezier_curves), config.max_curves)
    
    # Initialize tensors
    bezier_points = torch.zeros(1, config.max_curves, 4, 2)
    bezier_mask = torch.zeros(1, config.max_curves, 4, dtype=torch.bool)
    
    # Fill tensors with curve data
    for i in range(num_curves):
        curve = bezier_curves[i]
        bezier_points[0, i] = curve.control_points
        bezier_mask[0, i] = True  # Mark as valid
    
    return bezier_points, bezier_mask


def load_bezier_curves_from_dataset(
    dataset_path: str,
    character: Optional[str] = None,
    max_files: Optional[int] = None,
    config: Optional[BezierConfig] = None
) -> List[BezierCurve]:
    """
    Load bezier curves from dataset directory structure.
    
    Args:
        dataset_path: Path to bezier_curves_output_no_visualization directory
        character: Optional specific character to load (e.g., "吁")
        max_files: Maximum number of files to process
        config: BezierConfig for processing
        
    Returns:
        all_curves: Combined list of BezierCurve objects from all files
    """
    if config is None:
        config = BezierConfig()
    
    dataset_root = Path(dataset_path) / "chinese-calligraphy-dataset"
    all_curves = []
    
    files_processed = 0
    
    # Iterate through character directories
    for char_dir in dataset_root.iterdir():
        if not char_dir.is_dir():
            continue
            
        # Skip if specific character requested and this isn't it
        if character is not None and char_dir.name != character:
            continue
        
        # Process JSON files in character directory
        for json_file in char_dir.glob("*_bezier.json"):
            if max_files is not None and files_processed >= max_files:
                break
            
            try:
                # Load and convert bezier data
                bezier_data = load_bezier_json(str(json_file))
                curves = convert_json_to_bezier_curves(bezier_data, config)
                all_curves.extend(curves)
                
                files_processed += 1
                
            except Exception as e:
                print(f"Warning: Failed to process {json_file}: {e}")
                continue
        
        if max_files is not None and files_processed >= max_files:
            break
    
    print(f"Loaded {len(all_curves)} bezier curves from {files_processed} files")
    return all_curves


def create_bezier_dataset_batch(
    curves_list: List[List[BezierCurve]],
    config: Optional[BezierConfig] = None
) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    Create batched tensors from multiple curve sets.
    
    Args:
        curves_list: List of curve lists (one per batch item)
        config: BezierConfig for batch parameters
        
    Returns:
        bezier_points: [B, max_curves, 4, 2] batched control points
        bezier_masks: [B, max_curves, 4] batch of validity masks
    """
    if config is None:
        config = BezierConfig()
    
    batch_size = len(curves_list)
    bezier_points = torch.zeros(batch_size, config.max_curves, 4, 2)
    bezier_masks = torch.zeros(batch_size, config.max_curves, 4, dtype=torch.bool)
    
    for batch_idx, curves in enumerate(curves_list):
        points, mask = batch_bezier_curves(curves, config)
        bezier_points[batch_idx] = points[0]
        bezier_masks[batch_idx] = mask[0]
    
    return bezier_points, bezier_masks


def sample_bezier_curves_for_generation(
    dataset_path: str,
    num_samples: int = 1,
    character: Optional[str] = None,
    config: Optional[BezierConfig] = None
) -> Tuple[torch.Tensor, torch.Tensor, List[str]]:
    """
    Sample bezier curves for generation, returning batched tensors.
    
    Args:
        dataset_path: Path to bezier dataset
        num_samples: Number of samples to generate
        character: Optional specific character to sample from
        config: BezierConfig for processing
        
    Returns:
        bezier_points: [num_samples, max_curves, 4, 2] batched control points
        bezier_masks: [num_samples, max_curves, 4] validity masks
        sample_names: List of source file identifiers
    """
    if config is None:
        config = BezierConfig()
    
    # Load available JSON files
    dataset_root = Path(dataset_path) / "chinese-calligraphy-dataset"
    available_files = []
    
    for char_dir in dataset_root.iterdir():
        if not char_dir.is_dir():
            continue
        if character is not None and char_dir.name != character:
            continue
            
        for json_file in char_dir.glob("*_bezier.json"):
            available_files.append(json_file)
    
    if len(available_files) == 0:
        raise ValueError(f"No bezier files found in {dataset_path}")
    
    # Sample files
    if num_samples > len(available_files):
        print(f"Warning: Requested {num_samples} samples but only {len(available_files)} available")
        num_samples = len(available_files)
    
    sampled_files = np.random.choice(available_files, size=num_samples, replace=False)
    
    # Load and batch curves
    curves_list = []
    sample_names = []
    
    for json_file in sampled_files:
        try:
            bezier_data = load_bezier_json(str(json_file))
            curves = convert_json_to_bezier_curves(bezier_data, config)
            curves_list.append(curves)
            sample_names.append(json_file.stem)
        except Exception as e:
            print(f"Warning: Failed to process {json_file}: {e}")
            # Add empty curves to maintain batch size
            curves_list.append([])
            sample_names.append(f"failed_{json_file.stem}")
    
    bezier_points, bezier_masks = create_bezier_dataset_batch(curves_list, config)
    
    return bezier_points, bezier_masks, sample_names


def visualize_bezier_curves(
    bezier_curves: List[BezierCurve],
    output_path: Optional[str] = None,
    image_size: Tuple[int, int] = (256, 256)
) -> np.ndarray:
    """
    Create a visualization of bezier curves.
    
    Args:
        bezier_curves: List of BezierCurve objects to visualize
        output_path: Optional path to save visualization
        image_size: Size of output image
        
    Returns:
        vis_image: Visualization as numpy array
    """
    import matplotlib.pyplot as plt
    import matplotlib.patches as patches
    
    fig, ax = plt.subplots(1, 1, figsize=(8, 8))
    ax.set_xlim(-1, 1)
    ax.set_ylim(-1, 1)
    ax.set_aspect('equal')
    ax.invert_yaxis()  # Invert Y axis to match image coordinates
    
    colors = plt.cm.tab10(np.linspace(0, 1, len(bezier_curves)))
    
    for i, curve in enumerate(bezier_curves):
        points = curve.control_points.numpy()
        
        # Draw control polygon
        control_poly = patches.Polygon(points, fill=False, edgecolor=colors[i], alpha=0.5, linestyle='--')
        ax.add_patch(control_poly)
        
        # Draw control points
        ax.scatter(points[:, 0], points[:, 1], c=[colors[i]], s=50, alpha=0.8)
        
        # Draw bezier curve (approximate with many points)
        t_values = np.linspace(0, 1, 100)
        curve_points = []
        
        for t in t_values:
            # Cubic bezier evaluation
            p = (1-t)**3 * points[0] + 3*(1-t)**2*t * points[1] + 3*(1-t)*t**2 * points[2] + t**3 * points[3]
            curve_points.append(p)
        
        curve_points = np.array(curve_points)
        ax.plot(curve_points[:, 0], curve_points[:, 1], color=colors[i], linewidth=2)
    
    ax.set_title(f'Bézier Curves Visualization ({len(bezier_curves)} curves)')
    ax.grid(True, alpha=0.3)
    
    if output_path:
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
    
    # Convert to numpy array
    fig.canvas.draw()
    vis_image = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
    vis_image = vis_image.reshape(fig.canvas.get_width_height()[::-1] + (3,))
    
    plt.close(fig)
    
    return vis_image


# Example usage functions
def load_sample_bezier_data(dataset_path: str) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    Load a sample of bezier data for testing.
    
    Args:
        dataset_path: Path to bezier dataset
        
    Returns:
        bezier_points: [1, max_curves, 4, 2] sample bezier points
        bezier_mask: [1, max_curves, 4] validity mask
    """
    curves = load_bezier_curves_from_dataset(dataset_path, max_files=1)
    if len(curves) == 0:
        # Return empty tensors if no data found
        config = BezierConfig()
        return torch.zeros(1, config.max_curves, 4, 2), torch.zeros(1, config.max_curves, 4, dtype=torch.bool)
    
    return batch_bezier_curves(curves)


def get_dataset_statistics(dataset_path: str) -> Dict[str, Any]:
    """
    Get statistics about the bezier dataset.
    
    Args:
        dataset_path: Path to bezier dataset
        
    Returns:
        stats: Dictionary with dataset statistics
    """
    dataset_root = Path(dataset_path) / "chinese-calligraphy-dataset"
    
    total_files = 0
    total_characters = 0
    total_curves = 0
    characters = set()
    
    for char_dir in dataset_root.iterdir():
        if not char_dir.is_dir():
            continue
        
        characters.add(char_dir.name)
        
        for json_file in char_dir.glob("*_bezier.json"):
            total_files += 1
            
            try:
                bezier_data = load_bezier_json(str(json_file))
                total_characters += len(bezier_data['characters'])
                
                for character in bezier_data['characters']:
                    total_curves += len(character['bezier_curves'])
                    
            except Exception as e:
                print(f"Warning: Failed to process {json_file}: {e}")
                continue
    
    stats = {
        'total_files': total_files,
        'total_characters_unique': len(characters),
        'total_character_instances': total_characters,
        'total_bezier_curves': total_curves,
        'avg_curves_per_character': total_curves / max(1, total_characters),
        'character_set': sorted(list(characters))
    }
    
    return stats